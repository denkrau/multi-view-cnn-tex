\section{Conclusions}
\label{sec:discussion-conclusion}
The objective of this work is to classify objects using multi-views.
In particular the same objects are classified but with different applied color marks.
Furthermore, the information content of these multi-views is analyzed and how views with different color marks impact this and the actual classification.
This basic network architecture of \textit{Feng et al.} \cite{Feng2018} is used, that assigns views a discrimination and groups them accordingly.
This is manipulated by using the AlexNet architecture with a modified first convolutional layer.
Moreover, the view discrimination scores are placed at a different position in the network.
Furthermore, for each group a group shape descriptor is generated that are then combined to yield the final, compact shape descriptor that is used for classification.
This architecture yields satisfiable results with respect to its loss and accuracy.
Because it is trained with a subset of ModelNet10, a direct comparison with recent researches is not possible.
However, the closest network for comparison with the MVCNN and GVCNN is 4-0 because it classifies only objects and no color marks.
This network's test accuracy is 99.4\,\%, while MVCNN reaches 89.9\,\% and GVCNN 92.6\,\%.
However, the 4-6 network is competitive with 85.5\,\%.

The grouping mechanism shows that, in particular, with the addition of color classes the network gets more complicated, hence its loss increases and its accuracy decreases.
It is noticeable, that using 5 or 6 color classes, wrong predictions are very likely to be within the same category class but with the related single or double color mark of the same color.
This can presumably be coped by a larger dataset or a longer training due to no indicator of overfitting.
Furthermore, it is observed across all networks that presumably ranges of values in the final shape descriptor are defined that correspond to color classes.
The assumed hierarchy starts with blank color classes as the highest values.
This is followed by red, red-red, green, green-red and green-green.
In general, views showing no color mark are more discriminative than views showing one, because the network uses them for excluding color classes from its possible predictions.
In practical terms, this means, for example, that a robot does not necessarily need to capture an entire object in order to make an accurate prediction.