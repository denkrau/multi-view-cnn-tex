\subsection{Class Accuracies}
\label{sec:predictions-accuracies}
The class accuracies of the single-category networks are presented in \tabref{tab:single-category-accuracies}.
Each color class consists of multi-views of the same 27 objects but with the related color mark.
Supported by its small loss, the 0-3 network has an overall accuracy of $\alpha_{\text{p}}=100\,\%$.
The more color marks or color classes, respectively, are added, the worse the accuracies of the related networks get.
This decrease is significant for the 0-4 network compared to the 0-3 one but for the remaining ones only slightly, though.
Furthermore, it can be seen, that the accuracies of the blank objects are always exact across all networks.
Due to being the most simple case, it is not surprising.

Although the accuracies seem ordinary for the 0-4 network, the misclassifications are interesting.
It classifies five objects with a red color mark as blank objects.
Something similar happens for the green-red color marks.
There are five ones classified as green.
However, this is more understandable than the blank misclassifications, due to the actual existence of that color.
How those wrong predictions could happen is going to be discussed for all networks based on the actual views, but for reasons of overview only in the following subsection.

The 0-5 network classifies 14 objects as green-green when they only have one green color mark, hence the bad accuracy of this class.
This matches the most expected prediction error.
It is possible, that those color marks are placed next to each other and seem like a single one.
For the green-green class, only two multi-views of objects are predicted wrong.
In fact as the single-green class.
This shows, that the network generally prefers a green-green prediction.
Those misclassifications are expected to be compensated with more training epochs or data samples for learning better correlations.
The results of the 0-5 network are similar to the ones of 0-4.
14 objects with a green color mark are predicted as green-green ones, while the other way round only two are misclassified as single green color mark objects.

The 0-6 network predicts similar as well.
However, the single color mark as double color mark misclassifications are much better for the red one.
Only four red ones are misclassified while 12 green ones are misclassified.
The predictions vice versa are better for the green color mark, though.
Only two are wrongly predicted as a single color mark for the green ones and eight for the red ones.
It seems like the networks prefer double green color mark classifications and single red ones.
Because this is valid for all of them, taking the weight initialization as the reason is unlikely.
Moreover, for each object, the same optimal faces are colored, so an unbalanced learning due to the dataset is prevented.
But why exactly the networks behave like that remains unknown. 
%TODO why does the network prefer double green and single red?
\begin{table}[]
	\centering
	\caption{Accuracy $\alpha_{\text{p}}$ per class of single-category networks}
	\label{tab:single-category-accuracies}
	\begin{tabular}{l|llll}
		            & 0-3 & 0-4   & 0-5   & 0-6   \\ \hline
		Blank       & 1.0 & 1.0   & 1.0   & 1.0   \\
		Green       & 1.0 & 0.852 & 0.481 & 0.556 \\
		Red         & 1.0 & 0.815 & 0.963 & 0.852 \\
		Green-Red   &     & 0.815 & 0.889 & 1.0   \\
		Green-Green &     &       & 0.926 & 0.926 \\
		Red-Red     &     &       &       & 0.704 \\ \hline
		Overall		& 1.0 & 0.870 & 0.852 & 0.840 \\
	\end{tabular}
\end{table}

The per class type accuracies $\alpha_{\text{p}}$ of the four-category networks are shown in \tabref{tab:four-category-accuracies}.
The number after a category class refers to the number of its objects.
In general, they are slightly better than the ones of the single-category networks, though they are more complicated.
This is presumably due to the larger training sets.
The 4-0 network predicts five bathtub objects as sofas, one dresser object as a monitor and two sofa objects as dressers.
That seems like all object categories share some features for being able to misclassify them as different categories.
For example, if only bathtubs are misclassified as sofas and sofas are misclassified as bathtubs, it is certain that only those categories share features.
However, absolutely that are not many wrong predictions, so presumably a longer training should increase the accuracies by learning more discriminative features.

The 4-3 network predicts some bathtubs as sofas as well, but each predicted color class of them is correct.
In numbers, it is five, four and one wrong predictions per related color mark.
This shows, that at least for bathtubs green-red color marks can be classified accurately.
Furthermore, some dressers are mistaken for monitors and some sofas for dressers.
Those type of wrong predictions match the ones of the earlier network.
Moreover, a few colored objects are predicted as the related blank object.
This happens four times for sofas and once for monitors and dressers.

For the 4-4 network almost the same prediction characteristics are valid as for the earlier four-category networks.
The 4-5 and 4-6 networks experience a sudden drop in overall accuracy.
This was also the case with the single-category networks, but not that drastically.
Apparently, the double color marks are more challenging for multiple object categories due to more features.
Furthermore, both networks share some prediction characteristics of the earlier networks.
The favorite misclassification categories of the actual categories persist.
However, this is mostly valid for bathtubs.
The remaining categories mostly predict wrong color marks within their category class.

In particular the 4-5 network is really good with the dresser classes, however, its green-green class is the worst within that category.
For bathtubs, the single-green class is the worst within, because it has the most misclassifications in this category class with 6 objects as double-green bathtubs.
Vice versa only two objects are predicted wrong.
For dressers, monitors, and sofas the green-green classification has by far the worst accuracy within each category class.
The differences are 0.134, 0.36 and 0.154, respectively, to the second worst color class within each object category class.
In conclusion, this network shows, that the critical color classes are similar to the single-object networks, but it is more challenging for four-object networks to classify double color marks consistently.

This is almost completely supported by the 4-6 network, because it shares basically those characteristics of worst color classes within.
This time, though, the worst color classes for bathtubs and sofas are the single-green ones.
That confirms their correlation even more.
The single color mark classes for the remaining categories are balanced.
For the double color mark classes the red-red ones are the worst for bathtubs and monitors and the green-green ones for dressers and sofas.
Here it can be seen again, that usually one color is preferred over the other.
Nonetheless, usually, if a color is misclassified in double color mark networks, its prediction is either the single color or double color class of the same category class.

Presumably, all the errors presented in this section can be reduced by a longer training process, so that each network learns more and better correlations for predicting similar classes.
The possibility of this is supported by the loss against epoch graphs, that show no overfitting yet.
If this does not achieve the desired result, more data samples could be added for supplying more correlations to learn improved features.
\begin{table}[]
	\centering
	\caption[Accuracy per types of classes of four-category networks]{Accuracy per types of classes of four-category networks. The number after a category class refers to its number of objects.}
	\label{tab:four-category-accuracies}
	\begin{tabular}{l|lllll}
		            & 4-0   & 4-3   & 4-4   & 4-5   & 4-6   \\ \hline
		Bathtub (27)& 0.812 & 0.877 & 0.917 & 0.830 & 0.778 \\
		Dresser (30)& 0.967 & 0.967 & 0.942 & 0.960 & 0.911 \\
		Monitor (25)& 1.0   & 0.987 & 1.0   & 0.904 & 0.920 \\
		Sofa (26)   & 0.923 & 0.872 & 0.885 & 0.838 & 0.755 \\ \hline
		Blank       &       & 0.926 & 0.935 & 0.954 & 0.944 \\
		Green       &       & 0.926 & 0.944 & 0.870 & 0.722 \\
		Red         &       & 0.926 & 0.935 & 0.981 & 0.815 \\
		Green-Red   &       &       & 0.926 & 0.870 & 0.907 \\
		Green-Green &       &       &       & 0.750 & 0.843 \\
		Red-Red     &       &       &       &       & 0.822 \\ \hline
		Overall     & 0.926 & 0.926 & 0.935 & 0.885 & 0.842
	\end{tabular}
\end{table}